{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6911d37c-461a-49c0-b0c3-7ac1f3978cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/17 07:40:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Iniciar Sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RedditTextETL\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "644616b6-609d-4f1e-bea5-86c194b35768",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"hdfs://namenode:8020/data/reddit_depression_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "570eb11d-dfa2-4f1c-b4bd-d7e1c711e854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.csv(\n",
    "    file_path,\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    escape='\"',       # Ayuda a manejar comillas dentro de los campos\n",
    "    multiLine=True    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6ee5cce-a616-4ab4-b43e-863e59cb3d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- upvotes: integer (nullable = true)\n",
      " |-- created_utc: integer (nullable = true)\n",
      " |-- num_comments: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n",
      "+-----+------------+--------------------------------------------------+--------------------------------------------------+-------+-----------+------------+-----+\n",
      "|  _c0|   subreddit|                                             title|                                              body|upvotes|created_utc|num_comments|label|\n",
      "+-----+------------+--------------------------------------------------+--------------------------------------------------+-------+-----------+------------+-----+\n",
      "|47951|DeepThoughts|                            Deep thoughts underdog|Only when we start considering ourselves, the 9...|      4| 1405308909|        NULL|    0|\n",
      "|47952|DeepThoughts|I like this sub, there's only two posts yet I k...|Anyway: Human Morality is a joke so long as the...|      4| 1410568279|           1|    0|\n",
      "|47957|DeepThoughts|                                          Rebirth!|Hello. \\nI am the new guy in charge here (Besid...|      6| 1416457918|           1|    0|\n",
      "|47959|DeepThoughts|\"I want to be like water. I want to slip throug...|                                              NULL|     25| 1416512285|           2|    0|\n",
      "|47960|DeepThoughts|                                         Who am I?|You could take any one cell in my body and kill...|      5| 1416515812|           4|    0|\n",
      "|47969|DeepThoughts|What is the limit of the knowledge and power a ...|Personally, I think it's infinite. We will alwa...|      8| 1416683859|          23|    0|\n",
      "|47971|DeepThoughts|Nearly every major conflic, war, and genocide i...|                                              NULL|      6| 1416824367|           9|    0|\n",
      "|47973|DeepThoughts|                   10,000 Bits Contest (ChangeTip)|Hello, from now to Christmas we will be hosting...|      7| 1416869529|          26|    0|\n",
      "|47974|DeepThoughts|                              What is our purpose?|                                              NULL|      4| 1416870906|          14|    0|\n",
      "|47977|DeepThoughts|Just like bacteria live in our gut and are symb...|Do stars, solar systems, galaxies, all have con...|      8| 1416898017|          16|    0|\n",
      "|47978|DeepThoughts|            Life is something bigger than yourself|Human beings do not exist on their own.\\n\\nEver...|      4| 1416909656|           3|    0|\n",
      "|47979|DeepThoughts|If we could invade another planet full of intel...|Say a planet full of monkey-like creatures who ...|      7| 1416944537|          18|    0|\n",
      "|47980|DeepThoughts|   Do deep thoughts have to come from deep people?|Often people will be amazed when someone that t...|     12| 1416958552|           8|    0|\n",
      "|47983|DeepThoughts|What if humans are are pets for some celestial ...|                                              NULL|      8| 1417180725|          10|    0|\n",
      "|47984|DeepThoughts|freedom, probably more people have died for it ...|                                              NULL|      9| 1417208970|           3|    0|\n",
      "+-----+------------+--------------------------------------------------+--------------------------------------------------+-------+-----------+------------+-----+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()\n",
    "df_spark.show(15, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "649818c8-b453-4d76-bc76-14d8f5100b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando la distribución de clases en TODO el dataset cargado ---\n",
      "Distribución de la variable 'label':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "|    1| 480422|\n",
      "|    0|1990293|\n",
      "+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# --- Verificación de la Distribución de la Variable Objetivo 'label' ---\n",
    "print(\"--- Analizando la distribución de clases en TODO el dataset cargado ---\")\n",
    "\n",
    "# .groupBy(\"label\") agrupa todas las filas por el valor de la columna 'label'.\n",
    "# .count() cuenta cuántas filas hay en cada grupo.\n",
    "# .show() muestra el resultado.\n",
    "class_distribution = df_spark.groupBy(\"label\").count()\n",
    "\n",
    "print(\"Distribución de la variable 'label':\")\n",
    "class_distribution.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1977ca66-fdc0-424b-9769-35165fe3248d",
   "metadata": {},
   "source": [
    "Podemos observar que existen muchos mas comentarios clasificados como normales que deprimidos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5977f050-1d59-4a81-9125-8ea228f89cdb",
   "metadata": {},
   "source": [
    "## Pre-procesamiento y Limpieza con Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b4645d-46e8-413c-a0a4-d07c7e251457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat_ws, trim, lower\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e565090b-a57a-44c8-b382-d291be542bf6",
   "metadata": {},
   "source": [
    "Iniciamos la limpieza distribuida del dataset de Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "341c3c59-be35-4555-94f0-a4cb70176625",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_spark.dropna(subset=[\"Title\", \"Body\", \"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e843f8aa-4924-471b-ba29-fed62f298cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.withColumn(\"clean_text\", concat_ws(\" \", col(\"Title\"), col(\"Body\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00c89618-c1e1-428a-9589-e3e0bfe8501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim() quita espacios al inicio/final, lower() convierte a minúsculas.\n",
    "df_cleaned = df_cleaned.withColumn(\"clean_text_cleaned\", lower(trim(col(\"clean_text\"))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2cdf4-a8bb-403f-9bbb-6277c6fca5aa",
   "metadata": {},
   "source": [
    "Filtra entradas no validas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d99e4ab-20f2-4844-af6a-7736b2e09557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_cleaned.filter(\n",
    "    (col(\"clean_text_cleaned\") != \"\") & \n",
    "    (col(\"clean_text_cleaned\") != \"no content\") &\n",
    "    (col(\"clean_text_cleaned\").isNotNull())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893d223-34a4-43b6-b21e-fc368af409e7",
   "metadata": {},
   "source": [
    "Elimina Duplicados y selecciona las columnas finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e31baf6-24cc-4d83-85fa-ebef77c28b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con el texto y la etiqueta, y eliminamos filas idénticas.\n",
    "df_final = df_filtered.select(\n",
    "    col(\"clean_text\"), \n",
    "    col(\"Label\").alias(\"is_depression\") # Renombramos Label para claridad\n",
    ").dropDuplicates([\"clean_text\", \"is_depression\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21ed610f-2098-486e-904f-ad0a1b2c45c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "final_count = df_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caeff643-5e82-4dcf-b0f4-139221a31699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Limpieza completada. Número de filas final: 2009690\n"
     ]
    }
   ],
   "source": [
    "print(f\"✅ Limpieza completada. Número de filas final: {final_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85a00cbf-5119-4cf3-951e-e465de15efda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "inicial_count = df_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fae36a39-02d2-4fc4-8d41-30dac0ef7f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Limpieza completada. Número de filas inical: 2470715\n"
     ]
    }
   ],
   "source": [
    "print(f\"✅ Limpieza completada. Número de filas inical: {inicial_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c92a72a-101e-4057-9f68-e7784e687ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+-------------+\n",
      "|                                        clean_text|is_depression|\n",
      "+--------------------------------------------------+-------------+\n",
      "|The word 'may' means with equal significance, '...|            0|\n",
      "|what is love everyone has a different perspecti...|            0|\n",
      "|Is it more beneficial to be above average at ev...|            0|\n",
      "|Deep thoughts on Covid-19 \\nI’m not much of a w...|            0|\n",
      "|\"We delight in the beauty of the butterfly but ...|            0|\n",
      "|Something came to my thoughts So lately I’ve be...|            0|\n",
      "|I’ve deleted all my social media and it’s time ...|            0|\n",
      "|Monopoly is the most realistic game Because you...|            0|\n",
      "|People are actually smarter or capable of being...|            0|\n",
      "|You Exist Right Now And That's Bizarre https://...|            0|\n",
      "|I wanna leave this earth having at least impact...|            0|\n",
      "|The smarter we are getting, the more we are dis...|            0|\n",
      "|true happiness doesn't exist. We're all in sear...|            0|\n",
      "|I’m convinced that people can believe in anythi...|            0|\n",
      "|Coping with the unknown Isn't it insane that li...|            0|\n",
      "|anyone mind talking? I feel horrible my anxiety...|            0|\n",
      "|can i just say we live in a different Age it wa...|            0|\n",
      "|Being 'genuine' and 'true to yourself' DOES NOT...|            0|\n",
      "|Humans are scum We take, we steal, we drag peop...|            0|\n",
      "|credit/ debt/ &amp; interest in the afterlife? ...|            0|\n",
      "+--------------------------------------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_final.show(20, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8ab79a9-fc20-44fe-a383-c2f442b147d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Guardando el DataFrame limpio en formato Parquet en HDFS ---\n",
      "Esto evita la operación .toPandas() que puede fallar con datos grandes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataFrame limpio guardado en HDFS en: hdfs://namenode:8020/data/reddit_cleaned.parquet\n",
      "✅ Sesión de Spark detenida.\n"
     ]
    }
   ],
   "source": [
    "# --- Celda de Guardado Intermedio (Reemplaza la de .toPandas()) ---\n",
    "\n",
    "print(\"--- Guardando el DataFrame limpio en formato Parquet en HDFS ---\")\n",
    "print(\"Esto evita la operación .toPandas() que puede fallar con datos grandes.\")\n",
    "\n",
    "# Definimos una ruta en HDFS para guardar el resultado intermedio\n",
    "output_parquet_path = \"hdfs://namenode:8020/data/reddit_cleaned.parquet\"\n",
    "\n",
    "# .write.mode('overwrite').parquet() es la forma eficiente de guardar.\n",
    "# Guardará el resultado como una carpeta con múltiples archivos Parquet.\n",
    "df_final.write.mode('overwrite').parquet(output_parquet_path)\n",
    "\n",
    "print(f\"✅ DataFrame limpio guardado en HDFS en: {output_parquet_path}\")\n",
    "\n",
    "# Detener la sesión de Spark, ya no la necesitamos para los siguientes pasos\n",
    "spark.stop()\n",
    "print(\"✅ Sesión de Spark detenida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91a3194-2c20-4c76-bf35-2ef26331e67e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
